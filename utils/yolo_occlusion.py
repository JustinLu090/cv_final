#!/usr/bin/env python3
"""
yolo_occlusion.py - åŸºæ–¼ YOLO çš„ç‰©ä»¶åµæ¸¬é®æ“‹å·¥å…·
====================================================

ä½¿ç”¨ YOLOv8 åµæ¸¬å ´æ™¯ä¸­çš„ç‰©ä»¶ï¼ˆæ¤…å­ã€æ¡Œå­ã€æ²™ç™¼ç­‰ï¼‰ï¼Œ
ä¸¦åœ¨æŒ‡å®šå¹€ä¸­é®æ“‹é€™äº›ç‰©ä»¶ï¼Œç”¨æ–¼æ¸¬è©¦ GRU è¨˜æ†¶æ¢å¾©èƒ½åŠ›ã€‚

ä½¿ç”¨æ–¹å¼:
    from utils.yolo_occlusion import YOLOOccluder
    
    occluder = YOLOOccluder()
    occluded_img, objects = occluder.occlude_objects(
        image, 
        target_classes=['chair', 'couch', 'dining table']
    )
"""

import cv2
import numpy as np
from pathlib import Path
import torch

try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    YOLO_AVAILABLE = False
    print("âš ï¸ ultralytics æœªå®‰è£ï¼Œè«‹åŸ·è¡Œ: pip install ultralytics")


class YOLOOccluder:
    """
    YOLO ç‰©ä»¶é®æ“‹å™¨
    
    ä½¿ç”¨ YOLOv8 åµæ¸¬ç‰©ä»¶ä¸¦é®æ“‹
    """
    
    # COCO è³‡æ–™é›†é¡åˆ¥åç¨± (YOLOv8 é è¨­ä½¿ç”¨)
    COCO_CLASSES = {
        0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane',
        5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light',
        10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench',
        14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow',
        20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack',
        25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee',
        30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat',
        35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket',
        39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife',
        44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich',
        49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza',
        54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant',
        59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop',
        64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave',
        69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book',
        74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier',
        79: 'toothbrush'
    }
    
    # å®¤å…§å¸¸è¦‹ç‰©ä»¶ï¼ˆScanNet å ´æ™¯ï¼‰
    INDOOR_OBJECTS = ['chair', 'couch', 'bed', 'dining table', 'potted plant', 
                      'tv', 'laptop', 'book', 'vase', 'bottle']
    
    def __init__(self, model_size='m', confidence_threshold=0.25, device='cuda'):
        """
        åˆå§‹åŒ– YOLO é®æ“‹å™¨
        
        Args:
            model_size: YOLO æ¨¡å‹å¤§å° ('n', 's', 'm', 'l', 'x')
                       n = nano (æœ€å¿«ï¼Œæº–ç¢ºåº¦è¼ƒä½)
                       s = small
                       m = medium (æ¨è–¦)
                       l = large
                       x = xlarge (æœ€æ…¢ï¼Œæº–ç¢ºåº¦æœ€é«˜)
            confidence_threshold: ä¿¡å¿ƒåº¦é–¾å€¼ (é™ä½åˆ° 0.25 ä»¥åµæ¸¬æ›´å¤šç‰©ä»¶)
            device: é‹è¡Œè¨­å‚™
        """
        if not YOLO_AVAILABLE:
            raise ImportError("è«‹å®‰è£ ultralytics: pip install ultralytics")
        
        self.confidence_threshold = confidence_threshold
        self.device = device
        
        # è¼‰å…¥ YOLO æ¨¡å‹
        model_name = f'yolov8{model_size}.pt'
        print(f"ğŸ“¦ è¼‰å…¥ YOLO æ¨¡å‹: {model_name}")
        self.model = YOLO(model_name)
        
        # å¦‚æœæœ‰ GPU å‰‡ä½¿ç”¨
        if device == 'cuda' and torch.cuda.is_available():
            self.model.to('cuda')
        
        print(f"âœ… YOLO æ¨¡å‹å·²è¼‰å…¥ (device: {device})")
    
    def detect_objects(self, image, target_classes=None):
        """
        åµæ¸¬åœ–åƒä¸­çš„ç‰©ä»¶
        
        Args:
            image: PIL Image æˆ– numpy array (RGB)
            target_classes: ç›®æ¨™é¡åˆ¥åˆ—è¡¨ï¼ŒNone = åµæ¸¬æ‰€æœ‰é¡åˆ¥
        
        Returns:
            detections: list of dict, æ¯å€‹åŒ…å«:
                - class_name: é¡åˆ¥åç¨±
                - confidence: ä¿¡å¿ƒåº¦
                - bbox: [x1, y1, x2, y2]
                - area: é¢ç©
        """
        # è½‰æ›ç‚º numpy array
        if hasattr(image, 'convert'):  # PIL Image
            img_array = np.array(image)
        else:
            img_array = image
        
        # YOLO æ¨è«–
        results = self.model(img_array, conf=self.confidence_threshold, verbose=False)
        
        detections = []
        for result in results:
            boxes = result.boxes
            for box in boxes:
                cls_id = int(box.cls[0])
                class_name = self.COCO_CLASSES.get(cls_id, 'unknown')
                
                # éæ¿¾ç›®æ¨™é¡åˆ¥
                if target_classes and class_name not in target_classes:
                    continue
                
                confidence = float(box.conf[0])
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                area = (x2 - x1) * (y2 - y1)
                
                detections.append({
                    'class_name': class_name,
                    'confidence': confidence,
                    'bbox': [int(x1), int(y1), int(x2), int(y2)],
                    'area': int(area)
                })
        
        return detections
    
    def select_medium_object(self, detections, min_area_ratio=0.02, max_area_ratio=0.15):
        """
        å¾åµæ¸¬çµæœä¸­é¸æ“‡ä¸€å€‹ä¸­ç­‰å¤§å°çš„ç‰©ä»¶
        
        Args:
            detections: YOLO åµæ¸¬çµæœåˆ—è¡¨
            min_area_ratio: æœ€å°é¢ç©æ¯”ä¾‹ï¼ˆç›¸å°æ–¼åœ–ç‰‡ç¸½é¢ç©ï¼‰
            max_area_ratio: æœ€å¤§é¢ç©æ¯”ä¾‹
        
        Returns:
            selected_detection: é¸ä¸­çš„ç‰©ä»¶ï¼ŒNone å¦‚æœæ²’æœ‰ç¬¦åˆæ¢ä»¶çš„
        """
        if not detections:
            return None
        
        # å‡è¨­åœ–ç‰‡å¤§å°ï¼ˆå¯ä»¥å¾ç¬¬ä¸€å€‹ bbox æ¨ç®—ï¼‰
        if detections:
            # å¾ bbox æ¨ç®—åœ–ç‰‡å¤§è‡´å°ºå¯¸
            max_x = max(d['bbox'][2] for d in detections)
            max_y = max(d['bbox'][3] for d in detections)
            image_area = max_x * max_y
        else:
            return None
        
        # éæ¿¾ä¸­ç­‰å¤§å°çš„ç‰©ä»¶
        medium_objects = []
        for det in detections:
            area_ratio = det['area'] / image_area
            if min_area_ratio <= area_ratio <= max_area_ratio:
                medium_objects.append(det)
        
        if not medium_objects:
            # å¦‚æœæ²’æœ‰ä¸­ç­‰å¤§å°çš„ï¼Œé¸æ“‡æœ€æ¥è¿‘ä¸­é–“å¤§å°çš„
            sorted_dets = sorted(detections, key=lambda x: x['area'])
            if len(sorted_dets) > 0:
                mid_idx = len(sorted_dets) // 2
                return sorted_dets[mid_idx]
            return None
        
        # éš¨æ©Ÿé¸æ“‡ä¸€å€‹ä¸­ç­‰å¤§å°çš„ç‰©ä»¶
        import random
        return random.choice(medium_objects)
    
    def occlude_single_object(self, image, target_classes=None, occlusion_color=(0, 0, 0),
                              min_area_ratio=0.02, max_area_ratio=0.15, random_selection=True):
        """
        åµæ¸¬ä¸¦é®æ“‹å–®ä¸€ç‰©ä»¶ï¼ˆéš¨æ©Ÿé¸æ“‡ä¸­ç­‰å¤§å°ï¼‰
        
        Args:
            image: PIL Image æˆ– numpy array (RGB)
            target_classes: ç›®æ¨™é¡åˆ¥åˆ—è¡¨ï¼ŒNone = ä½¿ç”¨é è¨­å®¤å…§ç‰©ä»¶
            occlusion_color: é®æ“‹é¡è‰² (R, G, B)
            min_area_ratio: æœ€å°é¢ç©æ¯”ä¾‹
            max_area_ratio: æœ€å¤§é¢ç©æ¯”ä¾‹
            random_selection: æ˜¯å¦éš¨æ©Ÿé¸æ“‡ï¼ˆTrueï¼‰æˆ–é¸æ“‡æœ€æ¥è¿‘ä¸­é–“å¤§å°çš„ï¼ˆFalseï¼‰
        
        Returns:
            occluded_image: é®æ“‹å¾Œçš„åœ–åƒ (numpy array, RGB)
            selected_detection: è¢«é®æ“‹çš„ç‰©ä»¶ä¿¡æ¯
            all_detections: æ‰€æœ‰åµæ¸¬åˆ°çš„ç‰©ä»¶
        """
        # è½‰æ›ç‚º numpy array
        if hasattr(image, 'convert'):  # PIL Image
            img_array = np.array(image)
        else:
            img_array = image.copy()
        
        h, w = img_array.shape[:2]
        image_area = h * w
        
        # ä½¿ç”¨é è¨­å®¤å…§ç‰©ä»¶é¡åˆ¥
        if target_classes is None:
            target_classes = self.INDOOR_OBJECTS
        
        # åµæ¸¬ç‰©ä»¶
        all_detections = self.detect_objects(img_array, target_classes)
        
        if not all_detections:
            return img_array, None, []
        
        # é¸æ“‡ä¸­ç­‰å¤§å°çš„ç‰©ä»¶
        medium_objects = []
        for det in all_detections:
            area_ratio = det['area'] / image_area
            if min_area_ratio <= area_ratio <= max_area_ratio:
                medium_objects.append(det)
        
        # é¸æ“‡è¦é®æ“‹çš„ç‰©ä»¶
        if medium_objects:
            if random_selection:
                import random
                selected = random.choice(medium_objects)
            else:
                # é¸æ“‡æœ€æ¥è¿‘ä¸­é–“å¤§å°çš„
                selected = sorted(medium_objects, key=lambda x: x['area'])[len(medium_objects) // 2]
        else:
            # å¦‚æœæ²’æœ‰ä¸­ç­‰å¤§å°ï¼Œé¸æ“‡æœ€æ¥è¿‘ä¸­ç­‰å¤§å°çš„
            if not all_detections:
                return img_array, None, []
            sorted_dets = sorted(all_detections, key=lambda x: x['area'])
            selected = sorted_dets[len(sorted_dets) // 2]
        
        # é®æ“‹é¸ä¸­çš„ç‰©ä»¶
        x1, y1, x2, y2 = selected['bbox']
        cv2.rectangle(img_array, (x1, y1), (x2, y2), occlusion_color, -1)
        
        return img_array, selected, all_detections
    
    def occlude_multiple_objects(self, image, target_classes=None, occlusion_color=(0, 0, 0),
                                 min_area=2000, max_objects=3, size_preference='medium'):
        """
        åµæ¸¬ä¸¦é®æ“‹å¤šå€‹ç‰©ä»¶ï¼ˆæœ€å¤š max_objects å€‹ï¼‰
        
        Args:
            image: PIL Image æˆ– numpy array (RGB)
            target_classes: ç›®æ¨™é¡åˆ¥åˆ—è¡¨ï¼ŒNone = åµæ¸¬æ‰€æœ‰ç‰©ä»¶
            occlusion_color: é®æ“‹é¡è‰² (R, G, B)
            min_area: æœ€å°ç‰©ä»¶é¢ç©ï¼ˆé¿å…é®æ“‹å¤ªå°çš„ç‰©ä»¶ï¼‰
            max_objects: æœ€å¤šé®æ“‹å¹¾å€‹ç‰©ä»¶
            size_preference: ç‰©ä»¶å¤§å°åå¥½
                - 'medium': é¸æ“‡ä¸­ç­‰å¤§å°çš„ç‰©ä»¶
                - 'large': é¸æ“‡å¤§ç‰©ä»¶
                - 'small': é¸æ“‡å°ç‰©ä»¶
                - 'random': éš¨æ©Ÿé¸æ“‡
        
        Returns:
            occluded_image: é®æ“‹å¾Œçš„åœ–åƒ (numpy array, RGB)
            occluded_objects: è¢«é®æ“‹çš„ç‰©ä»¶åˆ—è¡¨
            all_detections: æ‰€æœ‰åµæ¸¬åˆ°çš„ç‰©ä»¶
        """
        # è½‰æ›ç‚º numpy array
        if hasattr(image, 'convert'):  # PIL Image
            img_array = np.array(image)
        else:
            img_array = image.copy()
        
        # åµæ¸¬ç‰©ä»¶ï¼ˆtarget_classes=None æœƒåµæ¸¬æ‰€æœ‰ç‰©ä»¶ï¼‰
        all_detections = self.detect_objects(img_array, target_classes=target_classes)
        
        if not all_detections:
            return img_array, [], []
        
        # éæ¿¾å¤ªå°çš„ç‰©ä»¶
        valid_detections = [d for d in all_detections if d['area'] >= min_area]
        
        if not valid_detections:
            return img_array, [], all_detections
        
        # æŒ‰é¢ç©æ’åº
        sorted_dets = sorted(valid_detections, key=lambda x: x['area'])
        
        # æ ¹æ“š size_preference é¸æ“‡ç‰©ä»¶
        # ğŸ†• å„ªå…ˆé¸ä¸­ç­‰ç‰©ä»¶ï¼Œå¦‚æœæ²’æœ‰å°±å¾€æ›´å¤§çš„æ‰¾
        if size_preference == 'medium':
            # ç­–ç•¥ï¼šä¸­ç­‰ (20%-80%) â†’ å¤§ (80%-100%) â†’ å…¨éƒ¨
            n = len(sorted_dets)
            start_medium = int(n * 0.2)
            end_medium = int(n * 0.8)
            
            # 1. å…ˆå˜—è©¦ä¸­ç­‰ç‰©ä»¶
            if end_medium > start_medium:
                candidate_objects = sorted_dets[start_medium:end_medium]
            else:
                candidate_objects = []
            
            # 2. å¦‚æœä¸­ç­‰ç‰©ä»¶ä¸å¤ ï¼ŒåŠ å…¥å¤§ç‰©ä»¶ (80%-100%)
            if len(candidate_objects) < max_objects and end_medium < n:
                large_objects = sorted_dets[end_medium:]
                candidate_objects.extend(large_objects)
                print(f"  ğŸ’¡ ä¸­ç­‰ç‰©ä»¶ä¸è¶³ï¼ŒåŠ å…¥ {len(large_objects)} å€‹å¤§ç‰©ä»¶")
            
            # 3. å¦‚æœé‚„æ˜¯ä¸å¤ ï¼ŒåŠ å…¥æ‰€æœ‰ç‰©ä»¶
            if len(candidate_objects) < max_objects:
                candidate_objects = sorted_dets
                print(f"  ğŸ’¡ ç‰©ä»¶ä¸è¶³ï¼Œä½¿ç”¨æ‰€æœ‰ {len(candidate_objects)} å€‹ç‰©ä»¶")
                
        elif size_preference == 'large':
            # é¸æ“‡å¤§ç‰©ä»¶ï¼ˆå‰ 50%ï¼‰
            n = len(sorted_dets)
            candidate_objects = sorted_dets[n//2:]
        elif size_preference == 'small':
            # é¸æ“‡å°ç‰©ä»¶ï¼ˆå¾Œ 50%ï¼‰
            n = len(sorted_dets)
            candidate_objects = sorted_dets[:n//2]
        else:  # random
            candidate_objects = valid_detections
        
        # éš¨æ©Ÿé¸æ“‡æœ€å¤š max_objects å€‹ç‰©ä»¶
        import random
        num_to_occlude = min(len(candidate_objects), max_objects)
        selected_objects = random.sample(candidate_objects, num_to_occlude)
        
        # é®æ“‹é¸ä¸­çš„ç‰©ä»¶
        for obj in selected_objects:
            x1, y1, x2, y2 = obj['bbox']
            cv2.rectangle(img_array, (x1, y1), (x2, y2), occlusion_color, -1)
        
        return img_array, selected_objects, all_detections
    
    def occlude_objects(self, image, target_classes=None, occlusion_color=(0, 0, 0),
                       min_area=1000, max_objects=5, occlusion_type='solid'):
        """
        åµæ¸¬ä¸¦é®æ“‹æŒ‡å®šç‰©ä»¶
        
        Args:
            image: PIL Image æˆ– numpy array (RGB)
            target_classes: ç›®æ¨™é¡åˆ¥åˆ—è¡¨ï¼ŒNone = ä½¿ç”¨é è¨­å®¤å…§ç‰©ä»¶
            occlusion_color: é®æ“‹é¡è‰² (R, G, B)
            min_area: æœ€å°ç‰©ä»¶é¢ç©ï¼ˆé¿å…é®æ“‹å¤ªå°çš„ç‰©ä»¶ï¼‰
            max_objects: æœ€å¤šé®æ“‹å¹¾å€‹ç‰©ä»¶
            occlusion_type: é®æ“‹é¡å‹
                - 'solid': ç´”è‰²é®æ“‹
                - 'noise': å™ªè²é®æ“‹
                - 'blur': æ¨¡ç³Šé®æ“‹
        
        Returns:
            occluded_image: é®æ“‹å¾Œçš„åœ–åƒ (numpy array, RGB)
            detections: åµæ¸¬åˆ°çš„ç‰©ä»¶åˆ—è¡¨
        """
        # è½‰æ›ç‚º numpy array
        if hasattr(image, 'convert'):  # PIL Image
            img_array = np.array(image)
        else:
            img_array = image.copy()
        
        # ä½¿ç”¨é è¨­å®¤å…§ç‰©ä»¶é¡åˆ¥
        if target_classes is None:
            target_classes = self.INDOOR_OBJECTS
        
        # åµæ¸¬ç‰©ä»¶
        detections = self.detect_objects(img_array, target_classes)
        
        # éæ¿¾å¤ªå°çš„ç‰©ä»¶
        detections = [d for d in detections if d['area'] >= min_area]
        
        # æŒ‰é¢ç©æ’åºï¼ˆå„ªå…ˆé®æ“‹å¤§ç‰©ä»¶ï¼‰
        detections.sort(key=lambda x: x['area'], reverse=True)
        
        # é™åˆ¶é®æ“‹æ•¸é‡
        detections = detections[:max_objects]
        
        # é®æ“‹ç‰©ä»¶
        occluded_count = 0
        for det in detections:
            x1, y1, x2, y2 = det['bbox']
            
            if occlusion_type == 'solid':
                # ç´”è‰²é®æ“‹
                cv2.rectangle(img_array, (x1, y1), (x2, y2), occlusion_color, -1)
            
            elif occlusion_type == 'noise':
                # å™ªè²é®æ“‹
                noise = np.random.randint(0, 255, (y2-y1, x2-x1, 3), dtype=np.uint8)
                img_array[y1:y2, x1:x2] = noise
            
            elif occlusion_type == 'blur':
                # æ¨¡ç³Šé®æ“‹
                roi = img_array[y1:y2, x1:x2]
                if roi.shape[0] > 0 and roi.shape[1] > 0:
                    kernel_size = max(51, min(roi.shape[0], roi.shape[1]) // 3)
                    if kernel_size % 2 == 0:
                        kernel_size += 1
                    blurred = cv2.GaussianBlur(roi, (kernel_size, kernel_size), 0)
                    img_array[y1:y2, x1:x2] = blurred
            
            occluded_count += 1
        
        return img_array, detections
    
    def visualize_detections(self, image, detections, show_labels=True):
        """
        è¦–è¦ºåŒ–åµæ¸¬çµæœï¼ˆç¹ªè£½é‚Šç•Œæ¡†ï¼‰
        
        Args:
            image: numpy array (RGB)
            detections: åµæ¸¬çµæœåˆ—è¡¨
            show_labels: æ˜¯å¦é¡¯ç¤ºæ¨™ç±¤
        
        Returns:
            vis_image: è¦–è¦ºåŒ–åœ–åƒ
        """
        img_vis = image.copy()
        
        for det in detections:
            x1, y1, x2, y2 = det['bbox']
            class_name = det['class_name']
            confidence = det['confidence']
            
            # ç¹ªè£½é‚Šç•Œæ¡†
            cv2.rectangle(img_vis, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # ç¹ªè£½æ¨™ç±¤
            if show_labels:
                label = f"{class_name} {confidence:.2f}"
                (text_w, text_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
                cv2.rectangle(img_vis, (x1, y1 - text_h - 4), (x1 + text_w, y1), (0, 255, 0), -1)
                cv2.putText(img_vis, label, (x1, y1 - 2), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
        
        return img_vis


def test_yolo_occlusion():
    """æ¸¬è©¦ YOLO é®æ“‹åŠŸèƒ½"""
    from PIL import Image
    
    print("=" * 70)
    print("æ¸¬è©¦ YOLO ç‰©ä»¶é®æ“‹")
    print("=" * 70)
    
    # è¼‰å…¥æ¸¬è©¦åœ–åƒ
    test_image_path = Path("scannet_data/scannet_frames_test/scene0757_00/color/0.jpg")
    
    if not test_image_path.exists():
        print(f"âŒ æ¸¬è©¦åœ–åƒä¸å­˜åœ¨: {test_image_path}")
        return
    
    image = Image.open(test_image_path).convert('RGB')
    print(f"âœ… è¼‰å…¥åœ–åƒ: {test_image_path}")
    
    # åˆå§‹åŒ–é®æ“‹å™¨
    occluder = YOLOOccluder(model_size='n', confidence_threshold=0.3)
    
    # åµæ¸¬ç‰©ä»¶
    print("\nğŸ“Š åµæ¸¬ç‰©ä»¶...")
    detections = occluder.detect_objects(image, target_classes=YOLOOccluder.INDOOR_OBJECTS)
    
    print(f"\nâœ… åµæ¸¬åˆ° {len(detections)} å€‹å®¤å…§ç‰©ä»¶:")
    for det in detections:
        print(f"   - {det['class_name']}: {det['confidence']:.2f} (area: {det['area']})")
    
    # é®æ“‹ç‰©ä»¶
    print("\nğŸ­ é®æ“‹ç‰©ä»¶...")
    occluded_img, occluded_dets = occluder.occlude_objects(
        image, 
        target_classes=['chair', 'couch', 'dining table'],
        occlusion_type='solid',
        max_objects=3
    )
    
    print(f"\nâœ… å·²é®æ“‹ {len(occluded_dets)} å€‹ç‰©ä»¶")
    
    # ä¿å­˜çµæœ
    output_dir = Path("test_output")
    output_dir.mkdir(exist_ok=True)
    
    # åŸåœ– + åµæ¸¬æ¡†
    vis_img = occluder.visualize_detections(np.array(image), detections)
    cv2.imwrite(str(output_dir / "yolo_detections.jpg"), 
                cv2.cvtColor(vis_img, cv2.COLOR_RGB2BGR))
    
    # é®æ“‹å¾Œ
    cv2.imwrite(str(output_dir / "yolo_occluded.jpg"),
                cv2.cvtColor(occluded_img, cv2.COLOR_RGB2BGR))
    
    print(f"\nâœ… çµæœå·²ä¿å­˜:")
    print(f"   - {output_dir / 'yolo_detections.jpg'}")
    print(f"   - {output_dir / 'yolo_occluded.jpg'}")


if __name__ == "__main__":
    test_yolo_occlusion()
